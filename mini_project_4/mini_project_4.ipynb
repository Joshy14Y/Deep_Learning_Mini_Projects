{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e288f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import (\n",
    "    ASTFeatureExtractor,\n",
    "    ASTForAudioClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f704f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPreprocessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init AST feature extractor.\"\"\"\n",
    "        self.feature_extractor = ASTFeatureExtractor.from_pretrained(\n",
    "            \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "        )\n",
    "\n",
    "    def extract_features(self, batch):\n",
    "        \"\"\"Extract audio feats.\"\"\"\n",
    "        features = self.feature_extractor(\n",
    "            raw_speech=[x[\"array\"] for x in batch[\"audio\"]],\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        batch[\"input_values\"] = features[\"input_values\"]\n",
    "        return batch\n",
    "\n",
    "    def preprocess(self, dataset):\n",
    "        \"\"\"Prep dataset for AST.\"\"\"\n",
    "        dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "        dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "        return dataset.map(\n",
    "            self.extract_features,\n",
    "            batched=True,\n",
    "            batch_size=32,\n",
    "            remove_columns=[\"audio\"],\n",
    "        )\n",
    "\n",
    "    def __call__(self, dataset):\n",
    "        \"Prep when called as a function.\"\n",
    "        return self.preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f748d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, audio_preprocessor):\n",
    "        \"\"\"Init preprocessing and loaders.\"\"\"\n",
    "        self.audio_preprocessor = audio_preprocessor\n",
    "        self.train, self.val = self.preprocess_splits(*self.get_data())\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Load train & val splits.\"\"\"\n",
    "        train = load_dataset(\"confit/esc50-parquet\", \"fold1\", split=\"train\")\n",
    "        val = load_dataset(\"confit/esc50-parquet\", \"fold1\", split=\"test\")\n",
    "        return train, val\n",
    "\n",
    "    def preprocess_splits(self, train, val):\n",
    "        \"\"\"Prep train & val.\"\"\"\n",
    "        train = self.audio_preprocessor(train)\n",
    "        val = self.audio_preprocessor(val)\n",
    "        return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfddf7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init evaluation metrics.\"\"\"\n",
    "        self.accuracy = evaluate.load(\"accuracy\")\n",
    "        self.f1 = evaluate.load(\"f1\")\n",
    "        self.precision = evaluate.load(\"precision\")\n",
    "        self.recall = evaluate.load(\"recall\")\n",
    "        self.average = 'micro'\n",
    "\n",
    "    def eval_accuracy(self, predictions, labels):\n",
    "        \"\"\"Compute accuracy.\"\"\"\n",
    "        return self.accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    def eval_f1(self, predictions, labels):\n",
    "        \"\"\"Compute F1 score.\"\"\"\n",
    "        return self.f1.compute(\n",
    "            predictions=predictions, references=labels, average=self.average\n",
    "        )\n",
    "\n",
    "    def eval_precision(self, predictions, labels):\n",
    "        \"\"\"Compute precision.\"\"\"\n",
    "        return self.precision.compute(\n",
    "            predictions=predictions, references=labels, average=self.average\n",
    "        )\n",
    "\n",
    "    def eval_recall(self, predictions, labels):\n",
    "        \"\"\"Compute recall.\"\"\"\n",
    "        return self.recall.compute(\n",
    "            predictions=predictions, references=labels, average=self.average\n",
    "        )\n",
    "    \n",
    "    def compute_metrics(self, eval_pred):\n",
    "        \"\"\"Compute all metrics.\"\"\"\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        metrics = {}\n",
    "        metrics.update(self.eval_accuracy(predictions, labels))\n",
    "        metrics.update(self.eval_f1(predictions, labels))\n",
    "        metrics.update(self.eval_precision(predictions, labels))\n",
    "        metrics.update(self.eval_recall(predictions, labels))\n",
    "        return metrics\n",
    "    \n",
    "    def __call__(self, eval_pred):\n",
    "        \"Compute all metrics when called as a function.\"\n",
    "        return self.compute_metrics(eval_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46eb0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Init training setup.\"\"\"\n",
    "        self.data = data\n",
    "        self.model = ASTForAudioClassification.from_pretrained(\n",
    "            \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "        )\n",
    "        self.metrics = Metrics()\n",
    "        self.args = TrainingArguments(\n",
    "            output_dir=\"./checkpoints\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=32,\n",
    "            learning_rate=2e-5,\n",
    "            num_train_epochs=5,\n",
    "            logging_strategy=\"no\",\n",
    "            save_strategy=\"best\",\n",
    "            load_best_model_at_end=True,\n",
    "        )\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=self.args,\n",
    "            train_dataset=data.train,\n",
    "            eval_dataset=data.val,\n",
    "            compute_metrics=self.metrics,\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Run training.\"\"\"\n",
    "        self.trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "    def val(self):\n",
    "        \"\"\"Run validation.\"\"\"\n",
    "        self.trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93c77c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshua/miniconda3/envs/deep_learning/lib/python3.11/site-packages/transformers/audio_utils.py:525: UserWarning: At least one mel filter has all zero values. The value for `num_mel_filters` (128) may be set too high. Or, the value for `num_frequency_bins` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_preprocessor = AudioPreprocessor()\n",
    "data = Data(audio_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d1a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 : < :, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = Train(data)\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d72470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31918656826019287,\n",
       " 'eval_accuracy': 0.93,\n",
       " 'eval_f1': 0.93,\n",
       " 'eval_precision': 0.93,\n",
       " 'eval_recall': 0.93,\n",
       " 'eval_runtime': 29.301,\n",
       " 'eval_samples_per_second': 13.651,\n",
       " 'eval_steps_per_second': 0.444,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
