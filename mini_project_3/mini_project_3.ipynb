{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e288f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bea0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Load BERT tokenizer and set max length.\"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.max_length = 512\n",
    "\n",
    "    def normalize(self, text):\n",
    "        \"\"\"Clean and normalize text.\"\"\"\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
    "        text = re.sub(r'\"\"+', '\"', text)\n",
    "        text = re.sub(r\"[\\n\\t\\r]+\", \" \", text)\n",
    "        text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "        text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "        text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "        text = re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", text)\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    def encode(self, normalized):\n",
    "        \"\"\"Tokenize text for BERT.\"\"\"\n",
    "        encoded = self.tokenizer(\n",
    "            normalized,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {k: v for k, v in encoded.items()}\n",
    "\n",
    "    def preprocess(self, texts):\n",
    "        \"\"\"Normalize and tokenize texts.\"\"\"\n",
    "        normalized = texts.apply(self.normalize).tolist()\n",
    "        return self.encode(normalized)\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        \"\"\"Preprocess texts.\"\"\"\n",
    "        return self.preprocess(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683fccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"Store encodings and labels.\"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of samples.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return item and label at given index.\"\"\"\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        label = self.labels[idx]\n",
    "        return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f748d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init preprocessing and loaders.\"\"\"\n",
    "        self.text_preprocessor = TextPreprocessor()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.setup_loaders()\n",
    "\n",
    "    def get_data(self, path=\"./data/bbc_text_cls.csv\"):\n",
    "        \"\"\"Load and encode CSV data.\"\"\"\n",
    "        df = pd.read_csv(path)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        X = df[\"text\"]\n",
    "        y = self.label_encoder.fit_transform(df[\"labels\"])\n",
    "        self.classes = self.label_encoder.classes_\n",
    "        return X, y\n",
    "\n",
    "    def split_data(self, X, y, random_state=42):\n",
    "        \"\"\"Split data into train, val, and test sets.\"\"\"\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "            X, y, test_size=0.3, stratify=y, random_state=random_state\n",
    "        )\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_eval, y_eval, test_size=1 / 3, stratify=y_eval, random_state=random_state\n",
    "        )\n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "    def create_loader(self, X, y, batch_size=32, shuffle=True):\n",
    "        \"\"\"Create DataLoader from dataset.\"\"\"\n",
    "        dataset = BertTextDataset(X, torch.tensor(y, dtype=torch.long))\n",
    "        return DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def encode_splits(self, X_train, X_val, X_test):\n",
    "        \"\"\"Preprocess train, val, and test splits.\"\"\"\n",
    "        X_train_tok = self.text_preprocessor.preprocess(X_train)\n",
    "        X_val_tok = self.text_preprocessor.preprocess(X_val)\n",
    "        X_test_tok = self.text_preprocessor.preprocess(X_test)\n",
    "        return X_train_tok, X_val_tok, X_test_tok\n",
    "\n",
    "    def setup_loaders(self):\n",
    "        \"\"\"Init train, val, and test loaders.\"\"\"\n",
    "        train, val, test = self.split_data(*self.get_data())\n",
    "        X_train_tok, X_val_tok, X_test_tok = self.encode_splits(\n",
    "            train[0], val[0], test[0]\n",
    "        )\n",
    "        self.train_loader = self.create_loader(X_train_tok, train[1])\n",
    "        self.val_loader = self.create_loader(X_val_tok, val[1], shuffle=False)\n",
    "        self.test_loader = self.create_loader(X_test_tok, test[1], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6382af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMetrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init metric counters.\"\"\"\n",
    "        self.reset_values()\n",
    "\n",
    "    def reset_values(self):\n",
    "        \"\"\"Reset all metric values.\"\"\"\n",
    "        self.loss = 0\n",
    "        self.acc = 0\n",
    "        self.correct_preds = 0\n",
    "        self.total_samples = 0\n",
    "\n",
    "    def update_loss(self, loss, batch_size):\n",
    "        \"\"\"Add batch loss to total.\"\"\"\n",
    "        self.loss += loss.item() * batch_size\n",
    "        self.total_samples += batch_size\n",
    "\n",
    "    def update_correct_preds(self, outputs, y):\n",
    "        \"\"\"Add correct predictions from batch.\"\"\"\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        self.correct_preds += (preds == y).sum().item()\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"Return average loss and accuracy.\"\"\"\n",
    "        avg_loss = self.loss / self.total_samples\n",
    "        avg_acc = self.correct_preds / self.total_samples\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Compute metrics when called.\"\"\"\n",
    "        return self.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c132281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCheckpoint:\n",
    "    def __init__(self, model, path=\"./checkpoints/best_model.pt\"):\n",
    "        \"\"\"Init checkpoint manager.\"\"\"\n",
    "        self.setup_path(path)\n",
    "        self.model = model\n",
    "        self.best_acc = 0\n",
    "\n",
    "    def setup_path(self, path):\n",
    "        \"\"\"Ensure checkpoint dir exists.\"\"\"\n",
    "        self.path = path\n",
    "        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n",
    "\n",
    "    def save(self, acc):\n",
    "        \"\"\"Save model if accuracy improves.\"\"\"\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            torch.save(self.model.state_dict(), self.path)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(self.path)\n",
    "        self.model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46eb0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, model, data, epochs=5, lr=2e-5, load_checkpoint=False):\n",
    "        \"\"\"Init training setup.\"\"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.model = model.to(self.device)\n",
    "        self.epochs = epochs\n",
    "        self.data = data\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr)\n",
    "        self.metrics = TrainMetrics()\n",
    "        self.setup_checkpoint(load_checkpoint)\n",
    "\n",
    "    def setup_checkpoint(self, load_checkpoint):\n",
    "        \"\"\"Init checkpoint and optionally load weights.\"\"\"\n",
    "        self.checkpoint = TrainCheckpoint(self.model)\n",
    "        if load_checkpoint:\n",
    "            self.checkpoint.load()\n",
    "\n",
    "    def to_device(self, X, y):\n",
    "        \"\"\"Move batch to device.\"\"\"\n",
    "        X = {k: v.to(self.device) for k, v in X.items()}\n",
    "        y = y.to(self.device)\n",
    "        return X, y\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        \"\"\"Compute outputs and loss.\"\"\"\n",
    "        outputs = self.model(**X, labels=y)\n",
    "        return outputs.logits, outputs.loss\n",
    "\n",
    "    def backward(self, loss):\n",
    "        \"\"\"Run backprop and optimizer step.\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_metrics(self, outputs, y, loss):\n",
    "        \"\"\"Update batch metrics.\"\"\"\n",
    "        batch_size = y.size(0)\n",
    "        self.metrics.update_loss(loss, batch_size)\n",
    "        self.metrics.update_correct_preds(outputs, y)\n",
    "\n",
    "    def run_epoch(self, train_mode=True):\n",
    "        \"\"\"Run one training or validation epoch.\"\"\"\n",
    "        loader = self.data.train_loader if train_mode else self.data.val_loader\n",
    "        self.metrics.reset_values()\n",
    "        self.model.train() if train_mode else self.model.eval()\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            for X, y in loader:\n",
    "                X, y = self.to_device(X, y)\n",
    "                outputs, loss = self.forward(X, y)\n",
    "                if train_mode:\n",
    "                    self.backward(loss)\n",
    "                self.update_metrics(outputs, y, loss)\n",
    "        return self.metrics()\n",
    "\n",
    "    def print_metrics(self, epoch, train_metrics, val_metrics):\n",
    "        \"\"\"Print epoch metrics.\"\"\"\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{self.epochs}] \"\n",
    "            f\"train: loss={train_metrics[0]:.4f}, acc={train_metrics[1]:.2%} | \"\n",
    "            f\"val: loss={val_metrics[0]:.4f}, acc={val_metrics[1]:.2%}\"\n",
    "        )\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Train model and validate each epoch.\"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            train_metrics = self.run_epoch(train_mode=True)\n",
    "            val_metrics = self.run_epoch(train_mode=False)\n",
    "            self.print_metrics(epoch, train_metrics, val_metrics)\n",
    "            self.checkpoint.save(val_metrics[1])\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Start training loop.\"\"\"\n",
    "        self.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdf6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self, classes):\n",
    "        \"\"\"Init confusion matrices.\"\"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.classes = classes\n",
    "        self.num_classes = len(classes)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset all to zeros.\"\"\"\n",
    "        shape = (self.num_classes, 2, 2)\n",
    "        self.cms = torch.zeros(shape, dtype=torch.int16, device=self.device)\n",
    "\n",
    "    def binarize(self, cls, preds, labels):\n",
    "        \"\"\"Binarize predictions and labels.\"\"\"\n",
    "        preds_bin = preds == cls\n",
    "        y_bin = labels == cls\n",
    "        return preds_bin, y_bin\n",
    "\n",
    "    def update_class(self, cls, preds, labels):\n",
    "        \"\"\"Update matrix for one class.\"\"\"\n",
    "        tp = (preds & labels).sum()\n",
    "        fp = (preds & ~labels).sum()\n",
    "        tn = (~preds & ~labels).sum()\n",
    "        fn = (~preds & labels).sum()\n",
    "        self.cms[cls] += torch.tensor(\n",
    "            [[tn, fp], [fn, tp]], dtype=torch.int16, device=self.device\n",
    "        )\n",
    "\n",
    "    def update(self, preds, labels):\n",
    "        \"\"\"Update matrices for all classes.\"\"\"\n",
    "        for cls in range(self.num_classes):\n",
    "            preds_bin, y_bin = self.binarize(cls, preds, labels)\n",
    "            self.update_class(cls, preds_bin, y_bin)\n",
    "\n",
    "    def precision(self, cls):\n",
    "        \"\"\"Compute precision for class.\"\"\"\n",
    "        tp = self.cms[cls, 1, 1]\n",
    "        fp = self.cms[cls, 0, 1]\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "    def recall(self, cls):\n",
    "        \"\"\"Compute recall for class.\"\"\"\n",
    "        tp = self.cms[cls, 1, 1]\n",
    "        fn = self.cms[cls, 1, 0]\n",
    "        return tp / (tp + fn)\n",
    "\n",
    "    def f1(self, cls):\n",
    "        \"\"\"Compute F1 for class.\"\"\"\n",
    "        p = self.precision(cls)\n",
    "        r = self.recall(cls)\n",
    "        return 2 * p * r / (p + r)\n",
    "\n",
    "    def accuracy(self, cls):\n",
    "        \"\"\"Compute accuracy for class.\"\"\"\n",
    "        tn = self.cms[cls, 0, 0]\n",
    "        fp = self.cms[cls, 0, 1]\n",
    "        fn = self.cms[cls, 1, 0]\n",
    "        tp = self.cms[cls, 1, 1]\n",
    "        total = tp + tn + fp + fn\n",
    "        return (tp + tn) / total\n",
    "\n",
    "    def print_metrics(self):\n",
    "        \"\"\"Print all metrics per class.\"\"\"\n",
    "        for cls in range(self.num_classes):\n",
    "            name = self.classes[cls].capitalize()\n",
    "            print(f\"{name}:\")\n",
    "            print(f\"Confusion Matrix:\\n{self.cms[cls]}\")\n",
    "            print(f\"Accuracy: {self.accuracy(cls):.2%}\")\n",
    "            print(f\"Precision: {self.precision(cls):.2%}\")\n",
    "            print(f\"Recall: {self.recall(cls):.2%}\")\n",
    "            print(f\"F1: {self.f1(cls):.2%}\\n\")\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Print metrics when called.\"\"\"\n",
    "        self.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8559304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def __init__(self, model, data):\n",
    "        \"\"\"Init model, test loader, and metrics.\"\"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.model = model\n",
    "        self.test_loader = data.test_loader\n",
    "        self.cm = ClassificationMetrics(data.classes)\n",
    "\n",
    "    def to_device(self, X, y):\n",
    "        \"\"\"Move batch to device.\"\"\"\n",
    "        X = {k: v.to(self.device) for k, v in X.items()}\n",
    "        y = y.to(self.device)\n",
    "        return X, y\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Evaluate model on test data.\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                X, y = self.to_device(X, y)\n",
    "                outputs = self.model(**X, labels=y)\n",
    "                preds = outputs.logits.argmax(dim=1)\n",
    "                self.cm.update(preds, y)\n",
    "        self.cm()\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Run evaluation.\"\"\"\n",
    "        return self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93c77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876d1a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(data.classes)\n",
    ")\n",
    "train = Train(model=model, data=data, load_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975f9e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business:\n",
      "Confusion Matrix:\n",
      "tensor([[162,   1],\n",
      "        [  1,  49]], device='cuda:0', dtype=torch.int16)\n",
      "Accuracy: 99.06%\n",
      "Precision: 98.00%\n",
      "Recall: 98.00%\n",
      "F1: 98.00%\n",
      "\n",
      "Entertainment:\n",
      "Confusion Matrix:\n",
      "tensor([[176,   0],\n",
      "        [  0,  37]], device='cuda:0', dtype=torch.int16)\n",
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1: 100.00%\n",
      "\n",
      "Politics:\n",
      "Confusion Matrix:\n",
      "tensor([[172,   1],\n",
      "        [  2,  38]], device='cuda:0', dtype=torch.int16)\n",
      "Accuracy: 98.59%\n",
      "Precision: 97.44%\n",
      "Recall: 95.00%\n",
      "F1: 96.20%\n",
      "\n",
      "Sport:\n",
      "Confusion Matrix:\n",
      "tensor([[162,   0],\n",
      "        [  0,  51]], device='cuda:0', dtype=torch.int16)\n",
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1: 100.00%\n",
      "\n",
      "Tech:\n",
      "Confusion Matrix:\n",
      "tensor([[177,   1],\n",
      "        [  0,  35]], device='cuda:0', dtype=torch.int16)\n",
      "Accuracy: 99.53%\n",
      "Precision: 97.22%\n",
      "Recall: 100.00%\n",
      "F1: 98.59%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = Test(model=model, data=data)()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
