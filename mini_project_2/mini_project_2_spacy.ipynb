{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e288f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bea0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Load spaCy model.\"\"\"\n",
    "        self.nlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\", \"textcat\"])\n",
    "\n",
    "    def normalize(self, text):\n",
    "        \"\"\"Clean and normalize text.\"\"\"\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
    "        text = re.sub(r'\"\"+', '\"', text)\n",
    "        text = re.sub(r\"[\\n\\t\\r]+\", \" \", text)\n",
    "        text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "        text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "        text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "        text = re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", text)\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    def preprocess(self, texts, max_size=256):\n",
    "        \"\"\"Normalize and embed texts.\"\"\"\n",
    "        normalized = texts.apply(self.normalize)\n",
    "        pipe = self.nlp.pipe(normalized, batch_size=1000)\n",
    "        embeddings = torch.zeros((len(texts), max_size, 300), dtype=torch.float32)\n",
    "        for i, doc in enumerate(pipe):\n",
    "            vectors = [t.vector.get() for t in doc if not t.is_stop][:max_size]\n",
    "            vectors_np = np.array(vectors, dtype=np.float32)\n",
    "            vector_tensor = torch.from_numpy(vectors_np)\n",
    "            embeddings[i, : vector_tensor.size(0), :] = vector_tensor\n",
    "            del vectors, vectors_np, vector_tensor\n",
    "        return embeddings\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        \"\"\"Preprocess texts when called.\"\"\"\n",
    "        return self.preprocess(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f748d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init preprocessing and loaders.\"\"\"\n",
    "        self.text_preprocessor = TextPreprocessor()\n",
    "        self.random_state = 42\n",
    "        self.setup_loaders()\n",
    "\n",
    "    def limit_words(self, text):\n",
    "        \"\"\"Limit text to a fixed number of words.\"\"\"\n",
    "        words = text.split()\n",
    "        return \" \".join(words[:256])\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Load and clean CSV data.\"\"\"\n",
    "        df = pd.read_csv(\"./data/movie.csv\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        X = df[\"text\"].apply(self.limit_words)\n",
    "        y = df[\"label\"].to_numpy()\n",
    "        return X, y\n",
    "\n",
    "    def split_data(self, X, y):\n",
    "        \"\"\"Split data into train/val/test.\"\"\"\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "            X, y, test_size=0.3, stratify=y, random_state=self.random_state\n",
    "        )\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_eval,\n",
    "            y_eval,\n",
    "            test_size=1 / 3,\n",
    "            stratify=y_eval,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "    def create_loader(self, X, y, shuffle=True):\n",
    "        \"\"\"Build DataLoader from tensors.\"\"\"\n",
    "        dataset = TensorDataset(X, torch.tensor(y, dtype=torch.float32).unsqueeze(-1))\n",
    "        return DataLoader(\n",
    "            dataset, batch_size=32, shuffle=shuffle, pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def embed_splits(self, X_train, X_val, X_test):\n",
    "        \"\"\"Embed train/val/test splits.\"\"\"\n",
    "        X_train_emb = self.text_preprocessor(X_train)\n",
    "        X_val_emb = self.text_preprocessor(X_val)\n",
    "        X_test_emb = self.text_preprocessor(X_test)\n",
    "        return X_train_emb, X_val_emb, X_test_emb\n",
    "\n",
    "    def setup_loaders(self):\n",
    "        \"\"\"Init train, val, and test loaders.\"\"\"\n",
    "        train, val, test = self.split_data(*self.get_data())\n",
    "        X_train_enc, X_val_enc, X_test_enc = self.embed_splits(\n",
    "            train[0], val[0], test[0]\n",
    "        )\n",
    "        self.train_loader = self.create_loader(X_train_enc, train[1])\n",
    "        self.val_loader = self.create_loader(X_val_enc, val[1], shuffle=False)\n",
    "        self.test_loader = self.create_loader(X_test_enc, test[1], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6382af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainMetrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init metric counters.\"\"\"\n",
    "        self.reset_values()\n",
    "\n",
    "    def reset_values(self):\n",
    "        \"\"\"Reset all metric values.\"\"\"\n",
    "        self.loss = 0\n",
    "        self.acc = 0\n",
    "        self.correct_preds = 0\n",
    "        self.total_samples = 0\n",
    "\n",
    "    def update_loss(self, loss, batch_size):\n",
    "        \"\"\"Add batch loss to total.\"\"\"\n",
    "        self.loss += loss.item() * batch_size\n",
    "        self.total_samples += batch_size\n",
    "\n",
    "    def update_correct_preds(self, outputs, y):\n",
    "        \"\"\"Add correct predictions from batch.\"\"\"\n",
    "        preds = torch.sigmoid(outputs) >= 0.5\n",
    "        self.correct_preds += (preds == y).sum().item()\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"Return average loss and accuracy.\"\"\"\n",
    "        avg_loss = self.loss / self.total_samples\n",
    "        avg_acc = self.correct_preds / self.total_samples\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Compute metrics when called.\"\"\"\n",
    "        return self.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c132281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCheckpoint:\n",
    "    def __init__(self, model):\n",
    "        \"\"\"Init checkpoint manager.\"\"\"\n",
    "        self.setup_path(\"./checkpoints/spacy/best_model.pt\")\n",
    "        self.model = model\n",
    "        self.best_acc = 0\n",
    "\n",
    "    def setup_path(self, path):\n",
    "        \"\"\"Ensure checkpoint dir exists.\"\"\"\n",
    "        self.path = path\n",
    "        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n",
    "\n",
    "    def save(self, acc):\n",
    "        \"\"\"Save model if accuracy improves.\"\"\"\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            torch.save(self.model.state_dict(), self.path)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(self.path)\n",
    "        self.model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, model, data, load_checkpoint=False):\n",
    "        \"\"\"Init training setup.\"\"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.model = model.to(self.device)\n",
    "        self.epochs = 100\n",
    "        self.data = data\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=1e-2)\n",
    "        self.metrics = TrainMetrics()\n",
    "        self.setup_checkpoint(load_checkpoint)\n",
    "\n",
    "    def setup_checkpoint(self, load_checkpoint):\n",
    "        \"\"\"Init checkpoint and optionally load weights.\"\"\"\n",
    "        self.checkpoint = TrainCheckpoint(self.model)\n",
    "        if load_checkpoint:\n",
    "            self.checkpoint.load()\n",
    "\n",
    "    def to_device(self, X, y):\n",
    "        \"\"\"Move batch to device.\"\"\"\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        return X, y\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        \"\"\"Compute outputs and loss.\"\"\"\n",
    "        outputs = self.model(X)\n",
    "        loss = self.criterion(outputs, y)\n",
    "        return outputs, loss\n",
    "\n",
    "    def backward(self, loss):\n",
    "        \"\"\"Run backprop and optimizer step.\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_metrics(self, outputs, y, loss):\n",
    "        \"\"\"Update batch metrics.\"\"\"\n",
    "        batch_size = y.size(0)\n",
    "        self.metrics.update_loss(loss, batch_size)\n",
    "        self.metrics.update_correct_preds(outputs, y)\n",
    "\n",
    "    def run_epoch(self, train_mode=True):\n",
    "        \"\"\"Run one training or validation epoch.\"\"\"\n",
    "        loader = self.data.train_loader if train_mode else self.data.val_loader\n",
    "        self.metrics.reset_values()\n",
    "        self.model.train() if train_mode else self.model.eval()\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            for X, y in loader:\n",
    "                X, y = self.to_device(X, y)\n",
    "                outputs, loss = self.forward(X, y)\n",
    "                if train_mode:\n",
    "                    self.backward(loss)\n",
    "                self.update_metrics(outputs, y, loss)\n",
    "        return self.metrics()\n",
    "\n",
    "    def print_metrics(self, epoch, train_metrics, val_metrics):\n",
    "        \"\"\"Print epoch metrics.\"\"\"\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{self.epochs}] \"\n",
    "            f\"train: loss={train_metrics[0]:.4f}, acc={train_metrics[1]:.2%} | \"\n",
    "            f\"val: loss={val_metrics[0]:.4f}, acc={val_metrics[1]:.2%}\"\n",
    "        )\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Train model and validate each epoch.\"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            train_metrics = self.run_epoch(train_mode=True)\n",
    "            val_metrics = self.run_epoch(train_mode=False)\n",
    "            self.print_metrics(epoch, train_metrics, val_metrics)\n",
    "            self.checkpoint.save(val_metrics[1])\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Start training loop.\"\"\"\n",
    "        self.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b6192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=300, hidden_dim=64, num_layers=2):\n",
    "        \"\"\"Init layers.\"\"\"\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        x = self.fc(hidden)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdf6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self):\n",
    "        \"\"\"Init confusion matrix on device.\"\"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset confusion matrix.\"\"\"\n",
    "        self.cm = torch.zeros((2, 2), dtype=torch.int16, device=self.device)\n",
    "\n",
    "    def update(self, preds, labels):\n",
    "        \"\"\"Update confusion matrix.\"\"\"\n",
    "        tp = ((preds == 1) & (labels == 1)).sum()\n",
    "        fp = ((preds == 1) & (labels == 0)).sum()\n",
    "        tn = ((preds == 0) & (labels == 0)).sum()\n",
    "        fn = ((preds == 0) & (labels == 1)).sum()\n",
    "        cm = torch.tensor([[tn, fp], [fn, tp]], dtype=torch.int16, device=self.device)\n",
    "        self.cm += cm\n",
    "\n",
    "    def precision(self):\n",
    "        \"\"\"Compute precision.\"\"\"\n",
    "        tp = self.cm[1, 1]\n",
    "        fp = self.cm[0, 1]\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"Compute recall.\"\"\"\n",
    "        tp = self.cm[1, 1]\n",
    "        fn = self.cm[1, 0]\n",
    "        return tp / (tp + fn)\n",
    "\n",
    "    def f1(self):\n",
    "        \"\"\"Compute F1 score.\"\"\"\n",
    "        p = self.precision()\n",
    "        r = self.recall()\n",
    "        return 2 * p * r / (p + r)\n",
    "\n",
    "    def accuracy(self):\n",
    "        \"\"\"Compute accuracy.\"\"\"\n",
    "        tn = self.cm[0, 0]\n",
    "        fp = self.cm[0, 1]\n",
    "        fn = self.cm[1, 0]\n",
    "        tp = self.cm[1, 1]\n",
    "        total = tp + tn + fp + fn\n",
    "        return (tp + tn) / total\n",
    "\n",
    "    def print_metrics(self):\n",
    "        \"\"\"Print confusion matrix and metrics.\"\"\"\n",
    "        print(f\"Confusion Matrix:\\n{self.cm}\")\n",
    "        print(f\"Accuracy: {self.accuracy():.2%}\")\n",
    "        print(f\"Precision: {self.precision():.2%}\")\n",
    "        print(f\"Recall: {self.recall():.2%}\")\n",
    "        print(f\"F1: {self.f1():.2%}\")\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Print metrics.\"\"\"\n",
    "        self.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8559304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def __init__(self, model, data):\n",
    "        \"\"\"Init model, test loader, and metrics.\"\"\"\n",
    "        self.device = \"cuda\"\n",
    "        self.model = model\n",
    "        self.test_loader = data.test_loader\n",
    "        self.cm = ClassificationMetrics()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Evaluate model on test data.\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                outputs = self.model(X)\n",
    "                preds = torch.sigmoid(outputs) >= 0.5\n",
    "                self.cm.update(preds, y)\n",
    "        self.cm()\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Run evaluation.\"\"\"\n",
    "        return self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93c77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.require_gpu()\n",
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a9784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "X_train = Train(model=model, data=data, load_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975f9e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "tensor([[1695,  287],\n",
      "        [ 225, 1766]], device='cuda:0', dtype=torch.int16)\n",
      "Accuracy: 87.11%\n",
      "Precision: 86.02%\n",
      "Recall: 88.70%\n",
      "F1: 87.34%\n"
     ]
    }
   ],
   "source": [
    "X_test = Test(model=model, data=data)()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
